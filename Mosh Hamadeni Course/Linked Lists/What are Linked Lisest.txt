We use linked lists to store a list of objects in equence. But unlike arrays, liked lists can grow and shrink automatically. As you can see here, a liked list consists of a group of nodes in sequence. Each node holds two pieces of data, one is a value, and another is the address of the next node in the list. So we say each node points to, or refrences the next node. That's why we refer to theses structures as linked lists, because these nodes are linked together. We call the first node 'head' and the last one 'tail'.

Now let's look at the time complexity fo various operations:
Let's say you want to find out if our list contains a given number. We have to traverse the list, starting from the head all the way to the tail. What is the run time complexity? It's O of n O(n). Because the value of what we're looking for may be stored in the last node, that is our worst case scenario, right?
What about looking up by index? Well, unlike arrays where items are stored sequentially, the nodes of a liked list can be all over the palce in memory, they may not be next to each other. That's why each node needs to keep a reference to the next node. For this reason, unlike arrays, we can not look up an itme by its index, we have to traverse the list until we find that item. In the worst case scenario, that item can be at the end of the list, so once again here we have O of n O(n).
What about insertions? Well, it depends where we want to insert the item. If you want to insert an item at the end, you simply want to creat a new node and have the last node or tail point to it. We should have a reference to the last node somewhere so we don't need to traverse the list everytime. Now we need to have the tail reference the new node. So inserting a new item at the end is an O of 1 O(1) operation.
What about inserting at the beginning, what do you think is the runtime complexity here? Here's the answer. It's an O of 1 O(1), because again, we should have a reference to the head or first node, so to insert a new item at the beginning of the list, we create a new node, link it to the first node, and then change the head to point to the new node, again this is very fast. Unlike arrays we don't have to copy or shit items around, we simply update the links or references.
Now what if you want to insert an item in the middle, let's say after the tenth node. Well first we need to find the node and that's an O of n operation, we then have to update the links which is an O of 1 operation. So inserting an item in the middle is an O of n operation.

Now let's talk about deletions. Deleting the first item is super fast. We simply set the head to point to the second node, that's an O of 1 operation. Now we need to remove the link from the previous head so it dosen't reference the second node anymore. Why? Because if we don't do this, Java's garbage collector thinks this item is still used, so it doesn't remove it from the memory, that's why we should unlink this from the second object. What about deleting the last item? This one is a bit tricky. We can easily get the tail, but we don't know the previous node, so we can't have the tail point to that node. How can we do that? We have to traverse the list from the head all the way to the tail, as soom as we get to the node before the last node, we keep a reference to it as the previous node, then we'll unlink this node from the last node. Then finally we have the tail point to the previous node. So the runtime complexity fo here is O of n, because we have to traverse the list all the way until the end. What about deleting form the middle? Again, we have to traverse the list to find the node, as well as the previous node. We should line the previous node to the node after this node, and then remove this link so this object gets removed from the memory by Java's garbage collector. Again we have an O of n operation.